{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fae6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from geolite2 import geolite2 \n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4ed63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countries_in_subgraph(G, subgraph_idx, field='country'):\n",
    "    '''\n",
    "    Given a NetworkX subgraph, generates the list of countries seen. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G (nx.Graph): the original graph\n",
    "    subgraph_idx (int): index number of the graph component\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_nodes (int): number of nodes in the subgraph\n",
    "    all_countries (list): list of all countries seen in the subgraph\n",
    "    '''\n",
    "    subgraphs = [nx.subgraph(G,c) for c in nx.connected_components(G)]\n",
    "    k = subgraphs[subgraph_idx]\n",
    "    # k = subgraph_list[subgraph_idx]\n",
    "    all_countries = []\n",
    "    all_nodes = []\n",
    "    num_nodes = len(k.nodes)\n",
    "    for node in k.nodes(data=True):\n",
    "        all_nodes.append(node[0])\n",
    "        try:\n",
    "            if str(node[1][field]) != 'nan':\n",
    "                all_countries.append(node[1][field])\n",
    "        except:\n",
    "            pass\n",
    "    return num_nodes, all_countries, all_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c4898",
   "metadata": {},
   "source": [
    "### My method\n",
    "\n",
    "My method of synthetic locations performs the following steps.\n",
    "\n",
    "1. Create a network of worker-miner-owner relationships using all historical data. \n",
    "2. Perform a lookup of the country from `geolite2`.\n",
    "3. My synthetic location algorithm\n",
    "    * Take the top 1000 connected subnetworks (can be more, but depends on how much spare time you have). \n",
    "    * For each subnetwork, label all miners by the modal location. (For example, if there are 10 miners in the subnetwork, 5 from China and 1 from Singapore, then all 10 miners are designated from China.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d16bcd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Preliminaries\n",
    "# 0a. Load lookup database\n",
    "geo = geolite2.reader()\n",
    "\n",
    "def extract_country(x):\n",
    "    out = np.nan\n",
    "    try:\n",
    "        # out = geo.get(x)['country']['names']['en']\n",
    "        out = geo.get(x)['country']['iso_code']\n",
    "    except:\n",
    "        pass\n",
    "    return out\n",
    "\n",
    "# 0b. Load worker relationship data\n",
    "data = pd.read_csv('../data/worker_relationship_jun_19.csv', index_col=[0])\n",
    "dsplt = data['multi_addresses'].str.split('/', expand=True)\n",
    "dsplt = dsplt[dsplt.columns[2]]\n",
    "data['ip'] = dsplt\n",
    "del dsplt\n",
    "\n",
    "# 0c. Extract country\n",
    "data['country'] = data['ip'].apply(extract_country)\n",
    "\n",
    "# 1. Load network\n",
    "# 1a. Add edges\n",
    "G = nx.Graph()\n",
    "for m,c in zip(data.miner_id, data.country):\n",
    "    G.add_node(m, country=c)\n",
    "G.add_edges_from([mi, wi] for mi, wi in data[['miner_id', 'worker_id']].drop_duplicates().values)\n",
    "G.add_edges_from([mi, oi] for mi, oi in data[['miner_id', 'owner_id']].drop_duplicates().values)\n",
    "\n",
    "# 1b. Remove small components\n",
    "small_components = sorted(nx.connected_components(G), key=len)[:-800]\n",
    "G.remove_nodes_from(itertools.chain.from_iterable(small_components))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e7fbaaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 800/800 [10:03<00:00,  1.33it/s]\n",
      "/var/folders/0_/1j63yf617y94nn64n_chcq580000gn/T/ipykernel_96659/2223059592.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  geo_df = pd.DataFrame(np.array([n_node_list, mode_country_list, n_geolocated_list, full_node_list]).T,\n"
     ]
    }
   ],
   "source": [
    "subgraphs = [nx.subgraph(G,c) for c in nx.connected_components(G)]\n",
    "number_of_subgraphs = len(subgraphs)\n",
    "n_node_list = []\n",
    "mode_country_list = []\n",
    "n_geolocated_list = []\n",
    "full_node_list = []\n",
    "\n",
    "for n in tqdm(range(number_of_subgraphs)):\n",
    "    n_nodes, all_c, all_nodes = countries_in_subgraph(G, n)\n",
    "    n_node_list.append(n_nodes)\n",
    "    full_node_list.append(all_nodes)\n",
    "    if len(all_c) > 0:\n",
    "        mode_country_list.append(stats.mode(all_c).mode[0])\n",
    "    else: \n",
    "        mode_country_list.append('None')\n",
    "    n_geolocated_list.append(len(all_c))\n",
    "\n",
    "geo_df = pd.DataFrame(np.array([n_node_list, mode_country_list, n_geolocated_list, full_node_list]).T, \n",
    "                      columns=['num_nodes', 'mode_country', 'num_geolocated_nodes', 'associated_nodes'])    \n",
    "geo_df.num_geolocated_nodes = pd.to_numeric(geo_df.num_geolocated_nodes)\n",
    "geo_df.num_nodes = pd.to_numeric(geo_df.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc17cb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0008979145211122554, 0.9533486740473739)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df[geo_df.num_geolocated_nodes > 0].sort_values(by='num_geolocated_nodes', ascending=False)\n",
    "geo_df['num_geolocated_nodes'].sum() / len(data), geo_df['num_nodes'].sum() / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "af50f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.to_csv('beng_method.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0208d",
   "metadata": {},
   "source": [
    "### Jim Pick method\n",
    "\n",
    "This method combines Jim Pick's inferred location with our own historical network data. \n",
    "\n",
    "1. Create a network of worker-miner-owner relationships using all historical data. \n",
    "2. Join this network table to Jim Pick's synthetic locations JSON.\n",
    "    * Note that I have calculated a column called `country_multi`, which contains all the countries seen for the given miner.\n",
    "3. My synthetic location algorithm\n",
    "    * Take the top 1000 connected subnetworks (can be more, but depends on how much spare time you have). \n",
    "    * (not fully implemented) Find out which are the countries seen in this subnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff347f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Read Jim's JSON file\n",
    "locations_jimpick = pd.read_json('https://geoip.feeds.provider.quest/synthetic-locations-latest.json')\n",
    "locations_df = pd.json_normalize(locations_jimpick.providerLocations)\n",
    "locations_df.index = locations_df.provider\n",
    "locations_df['country_multi'] = locations_df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd917e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Impute Jim's synthetic locations\n",
    "for prov in locations_df.provider.unique():\n",
    "    try:\n",
    "        if len(locations_df.loc[prov].country.unique())<2:\n",
    "            locations_df.country_multi.loc[prov]  = locations_df.loc[prov].country.unique()[0]\n",
    "        else:\n",
    "            locations_df.country_multi.loc[prov]  = str(locations_df.loc[prov].country.unique())\n",
    "    except:\n",
    "        locations_df.country_multi.loc[prov]   = locations_df.loc[prov].country\n",
    "lookup_df = locations_df[['provider', 'country_multi']].reset_index(drop=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f77bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Join our network table to Jim's locations\n",
    "data = pd.read_csv('../data/worker_relationship_jun_19.csv', index_col=[0])\n",
    "df_out = data.merge(lookup_df, how='left', left_on='miner_id', right_on='provider')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "36fd1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load network\n",
    "# 3a. Add edges\n",
    "G = nx.Graph()\n",
    "for m,c in zip(df_out.miner_id, df_out.country_multi):\n",
    "    G.add_node(m, country=c)\n",
    "G.add_edges_from([mi, wi] for mi, wi in data[['miner_id', 'worker_id']].drop_duplicates().values)\n",
    "G.add_edges_from([mi, oi] for mi, oi in data[['miner_id', 'owner_id']].drop_duplicates().values)\n",
    "\n",
    "# 3b. Remove small components\n",
    "small_components = sorted(nx.connected_components(G), key=len)[:-800]\n",
    "G.remove_nodes_from(itertools.chain.from_iterable(small_components))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b2f5dfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 800/800 [09:18<00:00,  1.43it/s]\n",
      "/var/folders/0_/1j63yf617y94nn64n_chcq580000gn/T/ipykernel_96659/2196042396.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  geo_df = pd.DataFrame(np.array([n_node_list, mode_country_list, n_geolocated_list, full_node_list]).T,\n"
     ]
    }
   ],
   "source": [
    "subgraphs = [nx.subgraph(G,c) for c in nx.connected_components(G)]\n",
    "number_of_subgraphs = len(subgraphs)\n",
    "n_node_list = []\n",
    "mode_country_list = []\n",
    "n_geolocated_list = []\n",
    "full_node_list = []\n",
    "\n",
    "for n in tqdm(range(number_of_subgraphs)):\n",
    "    n_nodes, all_c, all_nodes = countries_in_subgraph(G, n, field='country')\n",
    "    n_node_list.append(n_nodes)\n",
    "    full_node_list.append(all_nodes)\n",
    "    if len(all_c) > 0:\n",
    "        mode_country_list.append(stats.mode(all_c).mode[0])\n",
    "    else: \n",
    "        mode_country_list.append('None')\n",
    "    n_geolocated_list.append(len(all_c))\n",
    "\n",
    "geo_df = pd.DataFrame(np.array([n_node_list, mode_country_list, n_geolocated_list, full_node_list]).T, \n",
    "                      columns=['num_nodes', 'mode_country', 'num_geolocated_nodes', 'associated_nodes'])    \n",
    "geo_df.num_geolocated_nodes = pd.to_numeric(geo_df.num_geolocated_nodes)\n",
    "geo_df.num_nodes = pd.to_numeric(geo_df.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bed163f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0030606333676622037, 0.9508882595262615)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df[geo_df.num_geolocated_nodes > 0].sort_values(by='num_geolocated_nodes', ascending=False)\n",
    "geo_df['num_geolocated_nodes'].sum() / len(data), geo_df['num_nodes'].sum() / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9567a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.to_csv('jimpick_method.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
